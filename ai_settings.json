{
  "models": [
    {
      "name": "qwen3-4b-thinking",
      "type": "lmstudio",
      "base_url": "http://127.0.0.1:1234",
      "model_name": "qwen/qwen3-4b-thinking-2507",
      "temperature": 0.2,
      "max_tokens": 4000,
      "timeout": 60,
      "role": "conversation",
      "async": false,
      "top_p": 0.9,
      "frequency_penalty": 0.0,
      "presence_penalty": 0.0
    },
    {
      "name": "devstral-small",
      "type": "openai",
      "api_key": "your-api-key-here",
      "base_url": "http://127.0.0.1:1234/v1",
      "model_name": "mistralai/devstral-small-2507",
      "temperature": 0.3,
      "max_tokens": 3000,
      "timeout": 60,
      "role": "recording",
      "async": true,
      "top_p": 0.8
    },
    {
      "name": "gemma-3-4b",
      "type": "openai",
      "api_key": "your-api-key-here",
      "base_url": "http://127.0.0.1:1234/v1",
      "model_name": "local,google/gemma-3-4b",
      "temperature": 0.5,
      "max_tokens": 3000,
      "timeout": 60,
      "role": "archiving",
      "async": true,
      "top_p": 0.9
    },
    {
      "name": "gpt-oss-20b",
      "type": "openai",
      "api_key": "your-api-key-here",
      "base_url": "http://127.0.0.1:1234/v1",
      "model_name": "local,openai/gpt-oss-20b",
      "temperature": 0.1,
      "max_tokens": 4000,
      "timeout": 60,
      "role": "development",
      "async": true,
      "top_p": 0.9
    },
    {
      "name": "qwen3-coder-30b",
      "type": "openai",
      "api_key": "your-api-key-here",
      "base_url": "http://127.0.0.1:1234/v1",
      "model_name": "local,qwen/qwen3-coder-30b",
      "temperature": 0.1,
      "max_tokens": 4000,
      "timeout": 60,
      "role": "development",
      "async": true,
      "top_p": 0.9
    },
    {
      "name": "seed-oss-36b",
      "type": "openai",
      "api_key": "your-api-key-here",
      "base_url": "http://127.0.0.1:1234/v1",
      "model_name": "bytedance/seed-oss-36b",
      "temperature": 0.2,
      "max_tokens": 4000,
      "timeout": 60,
      "role": "complex_analysis",
      "async": true,
      "top_p": 0.9
    },
    {
      "name": "mock-provider",
      "type": "mock",
      "model_name": "mock-model",
      "temperature": 0.7,
      "max_tokens": 1000,
      "timeout": 5,
      "role": "testing",
      "async": false
    }
  ],
  "default_model": "qwen3-4b-thinking",
  "fallback_model": "qwen3-4b-thinking",
  "settings": {
    "auto_retry": true,
    "max_retries": 3,
    "retry_delay": 1.0,
    "rate_limit_delay": 0.5,
    "enable_logging": true,
    "log_level": "INFO"
  }
}
